# Evaluation Metrics Reference Guide
## Complete Metrics Definition for TSP Algorithm Assessment

**Purpose:** Comprehensive reference for evaluating and comparing optimization algorithms  
**Scope:** All metrics used in FIAP Tech Challenge Phase 2 algorithm analysis  
**Application:** Academic research, commercial evaluation, and algorithm selection  

---

## üìä Primary Performance Metrics

### **1. Solution Quality Metrics**

#### **Route Distance (km)**
- **Definition:** Total geographical distance of the complete TSP tour
- **Calculation:** Sum of Haversine distances between consecutive cities in route
- **Units:** Kilometers (converted from meters for readability)
- **Importance:** Primary optimization objective - lower is better
- **Formula:** `Œ£ haversine_distance(city[i], city[(i+1) % n])`

#### **Optimality Gap (%)**
- **Definition:** Percentage difference from best-known solution
- **Calculation:** `((algorithm_distance - best_distance) / best_distance) √ó 100`
- **Range:** 0% (optimal) to unlimited (worse solutions)
- **Interpretation:** 0% = optimal, <5% = excellent, <10% = good, >15% = poor
- **Usage:** Comparing relative algorithm performance

#### **Performance Ranking**
- **Definition:** Ordinal position among all tested algorithms
- **Method:** Rank algorithms by route distance (ascending order)
- **Notation:** ü•á (1st), ü•à (2nd), ü•â (3rd), numerical for others
- **Value:** Provides clear performance hierarchy

---

## ‚è±Ô∏è Computational Efficiency Metrics

### **2. Execution Time Metrics**

#### **Wall-Clock Time (seconds)**
- **Definition:** Total elapsed time from algorithm start to completion
- **Measurement:** Python `time.time()` before/after algorithm execution
- **Precision:** 4 decimal places (millisecond accuracy)
- **Includes:** All algorithm operations, data structures, and computations
- **Excludes:** Data loading, preprocessing, and result formatting

#### **Time Complexity Growth Factor**
- **Definition:** Rate of execution time increase per problem size increment
- **Calculation:** `time[n+1] / time[n] / (size[n+1] / size[n])`
- **Interpretation:** 
  - <1.5 = Excellent (sub-linear)
  - 1.5-2.5 = Good (near-linear) 
  - 2.5-4.0 = Moderate (polynomial)
  - >4.0 = Poor (exponential)
- **Application:** Scalability assessment for larger problems

#### **Efficiency Ratio**
- **Definition:** Solution quality achieved per unit time
- **Calculation:** `distance_quality / execution_time`
- **Units:** km/second (inverse - lower distance per time is better)
- **Usage:** Balancing quality vs speed requirements

---

## üíæ Resource Utilization Metrics

### **3. Memory Usage Metrics**

#### **Peak Memory Consumption (MB)**
- **Definition:** Maximum memory used during algorithm execution
- **Measurement:** Python `psutil` library monitoring RSS (Resident Set Size)
- **Baseline:** Memory usage delta from algorithm start to peak
- **Importance:** Critical for large-scale problem deployment
- **Calculation:** `peak_memory - baseline_memory`

#### **Memory Efficiency**
- **Definition:** Memory usage relative to problem size
- **Calculation:** `memory_mb / (number_of_cities¬≤)`
- **Units:** MB per city-pair
- **Interpretation:** Lower values indicate better memory utilization

#### **Memory Scalability**
- **Definition:** Rate of memory growth with increasing problem size
- **Assessment:** Linear, quadratic, or exponential growth patterns
- **Critical Threshold:** Available system memory limits

---

## üéØ Reliability and Consistency Metrics

### **4. Statistical Reliability**

#### **Standard Deviation (œÉ)**
- **Definition:** Measure of result variability across multiple runs
- **Calculation:** `‚àö(Œ£(x - Œº)¬≤ / (n-1))` where x = individual results, Œº = mean
- **Units:** Same as measured value (km for distance, seconds for time)
- **Interpretation:** Lower values indicate more consistent performance

#### **Coefficient of Variation (CV)**
- **Definition:** Normalized measure of variability
- **Calculation:** `(standard_deviation / mean) √ó 100`
- **Units:** Percentage
- **Interpretation:** <5% = excellent, 5-10% = good, >15% = inconsistent

#### **Success Rate (%)**
- **Definition:** Percentage of runs achieving satisfactory results
- **Criteria:** Valid TSP routes with reasonable solution quality
- **Calculation:** `(successful_runs / total_runs) √ó 100`
- **Threshold:** >95% for production algorithms

---

## üß¨ Algorithm-Specific Metrics

### **5. Genetic Algorithm Metrics**

#### **Generations to Convergence**
- **Definition:** Number of iterations required to find optimal solution
- **Measurement:** Generation when best fitness no longer improves
- **Range:** 1 to maximum_generations
- **Efficiency:** Fewer generations indicate faster convergence

#### **Population Diversity Score**
- **Definition:** Measure of genetic variation within population
- **Calculation:** Average pairwise distance between chromosomes
- **Range:** 0.0 (no diversity) to 1.0 (maximum diversity)
- **Optimal:** Maintain 0.3-0.7 throughout evolution

#### **Elite Preservation Rate**
- **Definition:** Percentage of best individuals retained across generations
- **Calculation:** `elite_size / population_size √ó 100`
- **Typical:** 5-20% for balanced exploration/exploitation

#### **Convergence Rate**
- **Definition:** Speed of fitness improvement over generations
- **Calculation:** `(initial_fitness - final_fitness) / generations`
- **Units:** Fitness improvement per generation
- **Interpretation:** Higher values indicate faster optimization

### **6. Ant Colony Optimization Metrics**

#### **Pheromone Trail Concentration**
- **Definition:** Accumulation of pheromone on optimal routes
- **Measurement:** Average pheromone level on best route edges
- **Range:** 0.0 to maximum pheromone limit
- **Convergence:** Increasing concentration on optimal paths

#### **Exploration vs Exploitation Balance**
- **Definition:** Ratio of new route discovery to best route following
- **Measurement:** Percentage of ants choosing unexplored edges
- **Optimal:** 20-30% exploration throughout iterations
- **Indicator:** Algorithm's ability to avoid local optima

#### **Colony Coordination Efficiency**
- **Definition:** How effectively ants share route information
- **Measurement:** Convergence rate of ant routes to optimal solution
- **Calculation:** Standard deviation of ant route distances per iteration
- **Goal:** Decreasing deviation indicates improving coordination

### **7. Particle Swarm Optimization Metrics**

#### **Swarm Diversity**
- **Definition:** Spatial distribution of particles in solution space
- **Calculation:** Average distance between particles
- **Range:** 0.0 (converged) to 1.0 (maximum spread)
- **Monitoring:** Should decrease gradually during optimization

#### **Velocity Convergence**
- **Definition:** Stabilization of particle movement patterns
- **Measurement:** Average velocity magnitude across swarm
- **Trend:** Should decrease as swarm converges to optimal solution
- **Indicator:** Algorithm stability and convergence quality

#### **Personal vs Global Best Influence**
- **Definition:** Balance between individual and social learning
- **Ratio:** Personal best discoveries vs global best adoptions
- **Optimal:** 60-70% global influence for good convergence
- **Adjustment:** Can be tuned based on problem characteristics

---

## üìà Advanced Performance Metrics

### **8. Convergence Analysis**

#### **Convergence Curve Slope**
- **Definition:** Rate of improvement in optimization objective
- **Calculation:** Linear regression slope of fitness vs iteration
- **Units:** Fitness improvement per iteration
- **Patterns:** Steep initial slope, gradual flattening indicates healthy convergence

#### **Plateau Detection**
- **Definition:** Identification of optimization stagnation periods
- **Measurement:** Number of consecutive iterations without improvement
- **Threshold:** Problem-specific (typically 10-20% of total iterations)
- **Action:** May trigger parameter adjustment or termination

#### **Final Solution Stability**
- **Definition:** Consistency of final results across independent runs
- **Measurement:** Standard deviation of best solutions from multiple runs
- **Goal:** Minimal variation in final solution quality
- **Reliability:** Indicates algorithm determinism and robustness

### **9. Scalability Assessment**

#### **Linear Scalability Factor**
- **Definition:** Degree to which performance scales linearly with problem size
- **Measurement:** Correlation coefficient between problem size and execution time
- **Range:** -1.0 to 1.0 (1.0 = perfect linear correlation)
- **Interpretation:** >0.9 = excellent scalability, >0.7 = good, <0.5 = poor

#### **Memory Scalability Classification**
- **Categories:**
  - **Constant:** O(1) - memory usage independent of problem size
  - **Linear:** O(n) - memory grows proportionally with cities
  - **Quadratic:** O(n¬≤) - memory grows with city pairs (distance matrix)
  - **Exponential:** O(2‚Åø) - memory grows exponentially (avoid for large problems)

#### **Practical Size Limits**
- **Definition:** Maximum problem size solvable within resource constraints
- **Constraints:** Available memory, acceptable execution time, solution quality
- **Measurement:** Largest successfully solved problem size
- **Planning:** Critical for production deployment decisions

---

## üéØ Quality Assessment Metrics

### **10. Solution Validation**

#### **Route Validity Check**
- **Definition:** Verification that solution forms valid TSP tour
- **Criteria:**
  - Visits each city exactly once
  - Returns to starting city
  - No duplicate or missing cities
  - Valid city indices within dataset range
- **Result:** Binary (valid/invalid) with detailed error reporting

#### **Distance Calculation Accuracy**
- **Definition:** Verification of distance computation correctness
- **Method:** Independent recalculation using same distance formula
- **Tolerance:** ¬±0.1% or ¬±0.1 km for floating-point precision
- **Importance:** Ensures fair algorithm comparison

#### **Geographical Constraint Compliance**
- **Definition:** Adherence to real-world transportation constraints
- **Verification:** Routes follow actual Brazilian transportation network
- **Constraints:** Physical connectivity, realistic travel distances
- **Application:** Real-world deployment validation

---

## üìä Comparative Analysis Metrics

### **11. Multi-Algorithm Comparison**

#### **Performance Matrix**
- **Structure:** Algorithms √ó Metrics cross-tabulation
- **Metrics:** Distance, time, memory, consistency for each algorithm
- **Ranking:** Ordinal position for each metric
- **Overall Score:** Weighted combination of individual metric ranks

#### **Category Performance Analysis**
- **Categories:** Evolutionary, Metaheuristic, Conventional
- **Aggregation:** Average performance across algorithms in each category
- **Comparison:** Statistical significance tests between categories
- **Insights:** Category-level strengths and weaknesses

#### **Pareto Frontier Analysis**
- **Definition:** Trade-off curve between competing objectives
- **Axes:** Solution quality vs execution time, quality vs memory usage
- **Identification:** Non-dominated solutions (cannot improve one metric without degrading another)
- **Application:** Multi-objective algorithm selection

### **12. Statistical Significance**

#### **Confidence Intervals**
- **Definition:** Range of values containing true performance with specified probability
- **Calculation:** `mean ¬± (t-statistic √ó standard_error)`
- **Confidence Level:** 95% (Œ± = 0.05) for academic standards
- **Interpretation:** Overlapping intervals indicate non-significant differences

#### **Hypothesis Testing**
- **Null Hypothesis:** No performance difference between algorithms
- **Alternative:** Significant performance difference exists
- **Test Statistics:** t-test for means, F-test for variances
- **p-value Threshold:** p < 0.05 for statistical significance

#### **Effect Size Measurement**
- **Definition:** Magnitude of performance difference between algorithms
- **Cohen's d:** `(mean1 - mean2) / pooled_standard_deviation`
- **Interpretation:** 0.2 = small, 0.5 = medium, 0.8 = large effect
- **Practical Significance:** Large effect sizes indicate meaningful differences

---

## üöÄ Practical Application Metrics

### **13. Real-World Deployment**

#### **Implementation Complexity**
- **Lines of Code:** Total implementation size
- **Dependencies:** Number and complexity of required libraries
- **Configuration:** Number of tunable parameters
- **Maintenance:** Estimated effort for updates and bug fixes

#### **Parameter Sensitivity**
- **Definition:** Algorithm robustness to parameter variations
- **Measurement:** Performance change with ¬±20% parameter modification
- **Robust Algorithms:** <5% performance degradation with parameter changes
- **Critical Parameters:** Those causing >10% performance impact

#### **Parallelization Potential**
- **Population-Based Algorithms:** Excellent (GA, PSO, ACO)
- **Sequential Algorithms:** Limited (Dijkstra, A*)
- **Speedup Factor:** Theoretical maximum with unlimited processors
- **Efficiency:** Actual speedup vs theoretical maximum

#### **Production Readiness Score**
- **Components:** Code quality, documentation, testing, performance, reliability
- **Scale:** 1-10 for each component
- **Threshold:** >8.0 overall for production deployment
- **Certification:** Ready for real-world transportation optimization

---

## üìã Metrics Summary Table

| **Category** | **Primary Metrics** | **Units** | **Optimal Range** | **Critical Threshold** |
|--------------|-------------------|-----------|-------------------|----------------------|
| **Quality** | Route Distance | km | 100-110 | <120 |
| **Quality** | Optimality Gap | % | 0-5% | <15% |
| **Efficiency** | Execution Time | seconds | 0.1-10 | <60 |
| **Efficiency** | Time Complexity | factor | 1.5-2.5 | <4.0 |
| **Resources** | Memory Usage | MB | 10-100 | <1000 |
| **Reliability** | Standard Deviation | km | 0-2 | <5 |
| **Reliability** | Success Rate | % | 95-100% | >90% |
| **Scalability** | Size Limit | cities | 100-1000 | >50 |

---

## üéØ Metric Selection Guidelines

### **For Academic Research:**
- **Primary:** Solution quality, statistical significance, convergence analysis
- **Secondary:** Algorithm-specific metrics, theoretical performance
- **Documentation:** Complete statistical analysis with confidence intervals

### **For Commercial Applications:**
- **Primary:** Execution time, memory usage, reliability, scalability
- **Secondary:** Implementation complexity, parameter sensitivity
- **Focus:** Production readiness and deployment feasibility

### **For Algorithm Development:**
- **Primary:** Convergence rate, parameter sensitivity, algorithmic behavior
- **Secondary:** Theoretical analysis, optimization potential
- **Goal:** Understanding and improving algorithm mechanisms

### **For Performance Benchmarking:**
- **Primary:** Comparative rankings, Pareto analysis, category performance
- **Secondary:** Statistical significance, effect sizes
- **Objective:** Fair and comprehensive algorithm comparison

---

**Reference Status:** ‚úÖ **COMPREHENSIVE METRICS DEFINED**  
**Application:** Universal algorithm evaluation framework  
**Coverage:** All aspects of TSP algorithm assessment  
**Usage:** Academic research, commercial evaluation, algorithm selection  

---

*This metrics reference provides the definitive framework for evaluating optimization algorithms in transportation networks, ensuring comprehensive, fair, and statistically valid performance assessment.*